{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.tsv', sep='\\t')\n",
    "df_test = pd.read_csv('test.tsv', sep='\\t')\n",
    "df.drop(['url'], axis=1, inplace=True)\n",
    "df_test.drop(['url'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/bina/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/bina/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "french_stopwords = stopwords.words(\"french\") + list(string.punctuation) + [\"''\", \"``\", \"...\", \"’\", \"``\", \"«\", \"»\", \"``\"]\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [token.lower() for token in tokens] # convert to lower case\n",
    "    tokens = [token for token in tokens if token.isalpha()] # remove punctuation\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95th percentile length of combined tokens: 1795\n"
     ]
    }
   ],
   "source": [
    "df_text = df['text'].apply(tokenize)\n",
    "df_headline = df['headline'].apply(tokenize)\n",
    "df['combined_tokens'] = df_text + df_headline\n",
    "df['length'] = df['combined_tokens'].apply(len)\n",
    "\n",
    "df_test_text = df_test['text'].apply(tokenize)\n",
    "df_test_headline = df_test['headline'].apply(tokenize)\n",
    "df_test['combined_tokens'] = df_test_text + df_test_headline\n",
    "df_test['length'] = df_test['combined_tokens'].apply(len) # used later to define padding\n",
    "\n",
    "max_length = int(np.percentile(df['length'], 95))  # Using 95th percentile to avoid outliers\n",
    "print(f\"95th percentile length of combined tokens: {max_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_tokens(tokens, max_length):\n",
    "    tokens = tokens[:max_length] + ['<pad>'] * max(0, max_length - len(tokens))\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['padded_tokens'] = df['combined_tokens'].apply(lambda x: pad_tokens(x, max_length))\n",
    "df_test['padded_tokens'] = df_test['combined_tokens'].apply(lambda x: pad_tokens(x, max_length))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df['encoded_category'] = label_encoder.fit_transform(df['category'])\n",
    "df_test['encoded_category'] = label_encoder.transform(df_test['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "      <th>combined_tokens</th>\n",
       "      <th>length</th>\n",
       "      <th>padded_tokens</th>\n",
       "      <th>encoded_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sports</td>\n",
       "      <td>L'Ouganda à l'assaut des \"fimbu\" de la RDC</td>\n",
       "      <td>L'Ouganda, placé 79e au classement FIFA le 4 a...</td>\n",
       "      <td>[placé, au, classement, fifa, le, avril, a, po...</td>\n",
       "      <td>319</td>\n",
       "      <td>[placé, au, classement, fifa, le, avril, a, po...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>Stopper la détérioration de l’environnement po...</td>\n",
       "      <td>La responsable de la biodiversité des Nations ...</td>\n",
       "      <td>[la, responsable, de, la, biodiversité, des, n...</td>\n",
       "      <td>585</td>\n",
       "      <td>[la, responsable, de, la, biodiversité, des, n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sports</td>\n",
       "      <td>Coupe d'Afrique des nations 2022 : le sélectio...</td>\n",
       "      <td>Le sélectionneur de la Sierra Leone, John Keis...</td>\n",
       "      <td>[le, sélectionneur, de, la, sierra, leone, joh...</td>\n",
       "      <td>305</td>\n",
       "      <td>[le, sélectionneur, de, la, sierra, leone, joh...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>Tissus africains : pourquoi les teintureries h...</td>\n",
       "      <td>Depuis plus de six siècles, une vaste zone sit...</td>\n",
       "      <td>[depuis, plus, de, six, siècles, une, vaste, z...</td>\n",
       "      <td>734</td>\n",
       "      <td>[depuis, plus, de, six, siècles, une, vaste, z...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>Les revenus pendant la pandémie des dix hommes...</td>\n",
       "      <td>Pendant la pandémie de coronavirus, la richess...</td>\n",
       "      <td>[pendant, la, pandémie, de, coronavirus, la, r...</td>\n",
       "      <td>598</td>\n",
       "      <td>[pendant, la, pandémie, de, coronavirus, la, r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>sports</td>\n",
       "      <td>C1: Le PSG va disputer sa toute première finale</td>\n",
       "      <td>Le Paris SG s'est qualifié pour sa toute premi...</td>\n",
       "      <td>[le, paris, sg, qualifié, pour, sa, toute, pre...</td>\n",
       "      <td>209</td>\n",
       "      <td>[le, paris, sg, qualifié, pour, sa, toute, pre...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>sports</td>\n",
       "      <td>Aubameyang invité à rejoindre un \"club plus am...</td>\n",
       "      <td>L'attaquant gabonais d'Arsenal, dont le contra...</td>\n",
       "      <td>[gabonais, dont, le, contrat, doit, expirer, à...</td>\n",
       "      <td>235</td>\n",
       "      <td>[gabonais, dont, le, contrat, doit, expirer, à...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>politics</td>\n",
       "      <td>Guerre Ukraine - Russie : qui est Sergey Surov...</td>\n",
       "      <td>La désignation de Sergey Surovikin pour dirige...</td>\n",
       "      <td>[la, désignation, de, sergey, surovikin, pour,...</td>\n",
       "      <td>862</td>\n",
       "      <td>[la, désignation, de, sergey, surovikin, pour,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>technology</td>\n",
       "      <td>Svetlana Jitomirskaya, la mathématicienne à l'...</td>\n",
       "      <td>Il existe un type de papillon qui captive le p...</td>\n",
       "      <td>[il, existe, un, type, de, papillon, qui, capt...</td>\n",
       "      <td>1540</td>\n",
       "      <td>[il, existe, un, type, de, papillon, qui, capt...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>sports</td>\n",
       "      <td>Maxwel Cornet rêve d'une finale avec le Sénégal</td>\n",
       "      <td>Il est l'arme secrète de la Côte d'Ivoire et i...</td>\n",
       "      <td>[il, est, secrète, de, la, côte, et, il, rêve,...</td>\n",
       "      <td>33</td>\n",
       "      <td>[il, est, secrète, de, la, côte, et, il, rêve,...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1476 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                           headline  \\\n",
       "0         sports         L'Ouganda à l'assaut des \"fimbu\" de la RDC   \n",
       "1       business  Stopper la détérioration de l’environnement po...   \n",
       "2         sports  Coupe d'Afrique des nations 2022 : le sélectio...   \n",
       "3       business  Tissus africains : pourquoi les teintureries h...   \n",
       "4       business  Les revenus pendant la pandémie des dix hommes...   \n",
       "...          ...                                                ...   \n",
       "1471      sports    C1: Le PSG va disputer sa toute première finale   \n",
       "1472      sports  Aubameyang invité à rejoindre un \"club plus am...   \n",
       "1473    politics  Guerre Ukraine - Russie : qui est Sergey Surov...   \n",
       "1474  technology  Svetlana Jitomirskaya, la mathématicienne à l'...   \n",
       "1475      sports    Maxwel Cornet rêve d'une finale avec le Sénégal   \n",
       "\n",
       "                                                   text  \\\n",
       "0     L'Ouganda, placé 79e au classement FIFA le 4 a...   \n",
       "1     La responsable de la biodiversité des Nations ...   \n",
       "2     Le sélectionneur de la Sierra Leone, John Keis...   \n",
       "3     Depuis plus de six siècles, une vaste zone sit...   \n",
       "4     Pendant la pandémie de coronavirus, la richess...   \n",
       "...                                                 ...   \n",
       "1471  Le Paris SG s'est qualifié pour sa toute premi...   \n",
       "1472  L'attaquant gabonais d'Arsenal, dont le contra...   \n",
       "1473  La désignation de Sergey Surovikin pour dirige...   \n",
       "1474  Il existe un type de papillon qui captive le p...   \n",
       "1475  Il est l'arme secrète de la Côte d'Ivoire et i...   \n",
       "\n",
       "                                        combined_tokens  length  \\\n",
       "0     [placé, au, classement, fifa, le, avril, a, po...     319   \n",
       "1     [la, responsable, de, la, biodiversité, des, n...     585   \n",
       "2     [le, sélectionneur, de, la, sierra, leone, joh...     305   \n",
       "3     [depuis, plus, de, six, siècles, une, vaste, z...     734   \n",
       "4     [pendant, la, pandémie, de, coronavirus, la, r...     598   \n",
       "...                                                 ...     ...   \n",
       "1471  [le, paris, sg, qualifié, pour, sa, toute, pre...     209   \n",
       "1472  [gabonais, dont, le, contrat, doit, expirer, à...     235   \n",
       "1473  [la, désignation, de, sergey, surovikin, pour,...     862   \n",
       "1474  [il, existe, un, type, de, papillon, qui, capt...    1540   \n",
       "1475  [il, est, secrète, de, la, côte, et, il, rêve,...      33   \n",
       "\n",
       "                                          padded_tokens  encoded_category  \n",
       "0     [placé, au, classement, fifa, le, avril, a, po...                 3  \n",
       "1     [la, responsable, de, la, biodiversité, des, n...                 0  \n",
       "2     [le, sélectionneur, de, la, sierra, leone, joh...                 3  \n",
       "3     [depuis, plus, de, six, siècles, une, vaste, z...                 0  \n",
       "4     [pendant, la, pandémie, de, coronavirus, la, r...                 0  \n",
       "...                                                 ...               ...  \n",
       "1471  [le, paris, sg, qualifié, pour, sa, toute, pre...                 3  \n",
       "1472  [gabonais, dont, le, contrat, doit, expirer, à...                 3  \n",
       "1473  [la, désignation, de, sergey, surovikin, pour,...                 2  \n",
       "1474  [il, existe, un, type, de, papillon, qui, capt...                 4  \n",
       "1475  [il, est, secrète, de, la, côte, et, il, rêve,...                 3  \n",
       "\n",
       "[1476 rows x 7 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = [token for tokens in df['padded_tokens'] for token in tokens]\n",
    "vocab = set(all_tokens)\n",
    "word_to_index = {word: idx for idx, word in enumerate(vocab)}\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        tokens = self.texts[idx]\n",
    "        indices = [word_to_index.get(token, len(vocab)) for token in tokens]\n",
    "        return torch.tensor(indices, dtype=torch.long), torch.tensor(self.labels[idx], dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(df['padded_tokens'].tolist(), df['encoded_category'].tolist(), test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextDataset(X_train, y_train)\n",
    "val_dataset = TextDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Text(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_classes, kernel_num=100, kernel_sizes=[3, 4, 5], dropout=0.5):\n",
    "        super(CNN_Text, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(1, kernel_num, (K, embed_dim)) for K in kernel_sizes])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(len(kernel_sizes) * kernel_num, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x).unsqueeze(1)  # (N, 1, max_length, embed_dim)\n",
    "        x = [nn.functional.relu(conv(x)).squeeze(3) for conv in self.convs]  # [(N, kernel_num, W), ...]*len(kernel_sizes)\n",
    "        x = [nn.functional.max_pool1d(line, line.size(2)).squeeze(2) for line in x]  # [(N, kernel_num), ...]*len(kernel_sizes)\n",
    "        x = torch.cat(x, 1)  # (N, kernel_num * len(kernel_sizes))\n",
    "        x = self.dropout(x)\n",
    "        logits = self.fc(x)  # (N, num_classes)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "vocab_size = len(vocab)\n",
    "embed_dim = 300  \n",
    "model = CNN_Text(vocab_size, embed_dim, num_classes)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}, Train Loss: {running_loss / len(train_loader)}, Val Loss: {val_loss / len(val_loader)}, Val Acc: {correct / total}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.856938207471693, Val Loss: 1.2453073024749757, Val Acc: 0.5878378378378378\n",
      "Epoch 2, Train Loss: 1.1350007121627395, Val Loss: 1.0019733428955078, Val Acc: 0.7128378378378378\n",
      "Epoch 3, Train Loss: 0.7827557550894247, Val Loss: 0.897068202495575, Val Acc: 0.7398648648648649\n",
      "Epoch 4, Train Loss: 0.5982036614740217, Val Loss: 0.8988564252853394, Val Acc: 0.7128378378378378\n",
      "Epoch 5, Train Loss: 0.4714181962850931, Val Loss: 0.8510267436504364, Val Acc: 0.7567567567567568\n",
      "Epoch 6, Train Loss: 0.382610909439422, Val Loss: 0.828895315527916, Val Acc: 0.7533783783783784\n",
      "Epoch 7, Train Loss: 0.3680238792219678, Val Loss: 0.8156717658042908, Val Acc: 0.7635135135135135\n",
      "Epoch 8, Train Loss: 0.2887197360396385, Val Loss: 0.7901791721582413, Val Acc: 0.7736486486486487\n",
      "Epoch 9, Train Loss: 0.25411405011608795, Val Loss: 0.8095291316509247, Val Acc: 0.7837837837837838\n",
      "Epoch 10, Train Loss: 0.17124696237009926, Val Loss: 0.7890667378902435, Val Acc: 0.8040540540540541\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
